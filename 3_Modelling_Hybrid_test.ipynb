{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa3b8cd-9616-4989-99a6-b1f2d05cbbe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, hamming_loss, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import hamming_loss as hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad787213-62f0-4a93-b16d-ba6855653b50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>new_genre</th>\n",
       "      <th>corpus</th>\n",
       "      <th>genre_length</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>animation</th>\n",
       "      <th>biography</th>\n",
       "      <th>comedy</th>\n",
       "      <th>crime</th>\n",
       "      <th>...</th>\n",
       "      <th>horror</th>\n",
       "      <th>music</th>\n",
       "      <th>musical</th>\n",
       "      <th>mystery</th>\n",
       "      <th>romance</th>\n",
       "      <th>sci-fi</th>\n",
       "      <th>sport</th>\n",
       "      <th>thriller</th>\n",
       "      <th>war</th>\n",
       "      <th>western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar: The Way of Water</td>\n",
       "      <td>Action,Adventure,Fantasy</td>\n",
       "      <td>jake sulli life newfound famili form extrasola...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Menu</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "      <td>young coupl travel remot island eat exclus res...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babylon</td>\n",
       "      <td>Comedy,Drama,History</td>\n",
       "      <td>tale outsiz ambit outrag excess trace rise fal...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Everything Everywhere All at Once</td>\n",
       "      <td>Action,Adventure,Comedy</td>\n",
       "      <td>middleag chines immigr swept insan adventur al...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M3gan</td>\n",
       "      <td>Horror,Sci-Fi,Thriller</td>\n",
       "      <td>robot engin toy compani build lifelik doll beg...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title                 new_genre  \\\n",
       "0           Avatar: The Way of Water  Action,Adventure,Fantasy   \n",
       "1                           The Menu           Horror,Thriller   \n",
       "2                            Babylon      Comedy,Drama,History   \n",
       "3  Everything Everywhere All at Once   Action,Adventure,Comedy   \n",
       "4                              M3gan    Horror,Sci-Fi,Thriller   \n",
       "\n",
       "                                              corpus  genre_length  action  \\\n",
       "0  jake sulli life newfound famili form extrasola...             3       1   \n",
       "1  young coupl travel remot island eat exclus res...             2       0   \n",
       "2  tale outsiz ambit outrag excess trace rise fal...             3       0   \n",
       "3  middleag chines immigr swept insan adventur al...             3       1   \n",
       "4  robot engin toy compani build lifelik doll beg...             3       0   \n",
       "\n",
       "   adventure  animation  biography  comedy  crime  ...  horror  music  \\\n",
       "0          1          0          0       0      0  ...       0      0   \n",
       "1          0          0          0       0      0  ...       1      0   \n",
       "2          0          0          0       1      0  ...       0      0   \n",
       "3          1          0          0       1      0  ...       0      0   \n",
       "4          0          0          0       0      0  ...       1      0   \n",
       "\n",
       "   musical  mystery  romance  sci-fi  sport  thriller  war  western  \n",
       "0        0        0        0       0      0         0    0        0  \n",
       "1        0        0        0       0      0         1    0        0  \n",
       "2        0        0        0       0      0         0    0        0  \n",
       "3        0        0        0       0      0         0    0        0  \n",
       "4        0        0        0       1      0         1    0        0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('finalmovie.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622a87cc-a714-4356-b91b-098b7769ef17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df['corpus']\n",
    "y = df['new_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5e5a15-9943-4aa7-afd8-0cb1e059cf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e314bb47-e264-4109-adc2-b8ee9a578d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train Word2Vec model\n",
    "sentences = [doc.split() for doc in X]\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe7c92c-eaed-429c-8339-05aace56073f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Compute TF-IDF scores\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_scores = tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddb9ea03-d774-4747-a376-1b41d33ea309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine Word2Vec vectors and TF-IDF scores\n",
    "hybrid_vectors = []\n",
    "for i, doc in enumerate(X):\n",
    "    tfidf_scores_doc = tfidf_scores[i].toarray()[0]\n",
    "    word_vectors_doc = []\n",
    "    for word in doc.split():\n",
    "        if word in w2v_model.wv.key_to_index:\n",
    "            word_vector = w2v_model.wv[word]\n",
    "            if word in tfidf_vectorizer.vocabulary_:\n",
    "                word_vector_tfidf = word_vector * tfidf_scores_doc[tfidf_vectorizer.vocabulary_[word]]\n",
    "            else:\n",
    "                word_vector_tfidf = word_vector\n",
    "            word_vectors_doc.append(word_vector_tfidf)\n",
    "    if word_vectors_doc:\n",
    "        doc_vector = np.mean(word_vectors_doc, axis=0)\n",
    "    else:\n",
    "        doc_vector = np.zeros(w2v_model.vector_size)\n",
    "    hybrid_vectors.append(doc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5891776-5f9d-4d1c-af11-e4b0ac4c0137",
   "metadata": {},
   "source": [
    "### starting testing oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed306deb-7c26-41e9-a314-9405851730d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply random oversampling\n",
    "oversampler = RandomOverSampler(sampling_strategy='all')\n",
    "X_resampled, y_resampled = oversampler.fit_resample(hybrid_vectors, y)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ff104-3f15-4ae9-8f51-f61cfd88fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(hybrid_vectors_tsne, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db77103-446b-4b4e-be3b-dfad3c984719",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # \"Single Vector Machine\": LinearSVC(),\n",
    "    # \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model on the resampled data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print classification report and confusion matrix\n",
    "    # print(f\"Model: {model_name}\")\n",
    "    # print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    # print(\"Hamming Loss: {:.3f}\".format(hamming_loss(y_test, y_pred)))\n",
    "    # print(classification_report(y_test, y_pred, zero_division=1))\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"Hamming Loss: {:.3f}\".format(hl(y_test, y_pred)))\n",
    "    print(\"F1-Score: {:.3f}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "    print(\"Precision: {:.3f}\".format(precision_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "    print(\"Recall: {:.3f}\".format(recall_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13014133-3473-4374-b3fb-31e3de438319",
   "metadata": {},
   "source": [
    "### ending oversampling test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed24c1-4e86-46c0-a839-1db31ed45434",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a645e058-7038-4f2a-878d-8a187a1fda19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create PCA object with 50 principal components\n",
    "pca = PCA(n_components=50)\n",
    "\n",
    "# Apply PCA to hybrid vectors\n",
    "hybrid_vectors_pca = pca.fit_transform(hybrid_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98b2873c-082a-48f2-8d05-a208969b9236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "hybrid_vectors = np.array(hybrid_vectors)\n",
    "# Create t-SNE object with 2 dimensions\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "# Apply t-SNE to hybrid vectors\n",
    "hybrid_vectors_tsne = tsne.fit_transform(hybrid_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a742432e-9659-43cd-9518-a7d8db72c7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(hybrid_vectors_tsne, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2cb12bd-b231-4322-a63a-cdf86cd38960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "Accuracy: 0.733\n",
      "Hamming Loss: 0.267\n",
      "F1-Score: 0.700\n",
      "Precision: 0.715\n",
      "Recall: 0.721\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.738\n",
      "Hamming Loss: 0.262\n",
      "F1-Score: 0.717\n",
      "Precision: 0.742\n",
      "Recall: 0.726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    # \"Single Vector Machine\": LinearSVC(),\n",
    "    # \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model on the resampled data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print classification report and confusion matrix\n",
    "    # print(f\"Model: {model_name}\")\n",
    "    # print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    # print(\"Hamming Loss: {:.3f}\".format(hamming_loss(y_test, y_pred)))\n",
    "    # print(classification_report(y_test, y_pred, zero_division=1))\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"Hamming Loss: {:.3f}\".format(hl(y_test, y_pred)))\n",
    "    print(\"F1-Score: {:.3f}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "    print(\"Precision: {:.3f}\".format(precision_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "    print(\"Recall: {:.3f}\".format(recall_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af179469-8bc7-4a42-a557-9ebf0d1b8ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10fe20-888b-4fd4-b562-8cb112366918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3446f-e206-4264-9746-f58a928947f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72846ce-5f1d-46e2-981f-b8f747c61398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8ea81-740f-4c88-a1c5-007c2bc3e56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1a2cc-f3e9-44a4-8db3-a241b44c774e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc9abc-7998-4be0-8a7a-4e8a94950e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e05ad674-04c8-4361-8b0d-48a446ac1980",
   "metadata": {},
   "source": [
    "### test end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992cc5a9-8697-40d0-82ea-e0c7f2564a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "168896f1-9595-49ec-b73c-560afa6c6840",
   "metadata": {},
   "source": [
    "# Working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb62a1-7dad-4416-83c1-0e71a0f858b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22614ad1-1f75-4f0a-904d-9a847ba247d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(hybrid_vectors, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4712f1-abbd-4398-b497-6900b8190545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Single Vector Machine\n",
      "Accuracy: 0.179\n",
      "Hamming Loss: 0.821\n",
      "F1-Score: 0.032\n",
      "Precision: 0.818\n",
      "Recall: 0.031\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.180\n",
      "Hamming Loss: 0.820\n",
      "F1-Score: 0.012\n",
      "Precision: 0.832\n",
      "Recall: 0.013\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.734\n",
      "Hamming Loss: 0.266\n",
      "F1-Score: 0.703\n",
      "Precision: 0.732\n",
      "Recall: 0.725\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.757\n",
      "Hamming Loss: 0.243\n",
      "F1-Score: 0.805\n",
      "Precision: 0.968\n",
      "Recall: 0.724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Single Vector Machine\": LinearSVC(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model on the resampled data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print classification report and confusion matrix\n",
    "    # print(f\"Model: {model_name}\")\n",
    "    # print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    # print(\"Hamming Loss: {:.3f}\".format(hamming_loss(y_test, y_pred)))\n",
    "    # print(classification_report(y_test, y_pred, zero_division=1))\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "    print(\"Hamming Loss: {:.3f}\".format(hl(y_test, y_pred)))\n",
    "    print(\"F1-Score: {:.3f}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "    print(\"Precision: {:.3f}\".format(precision_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "    print(\"Recall: {:.3f}\".format(recall_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "    # print(\"Confusion Matrix:\")\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d2231-d18c-4e93-8e23-ce8ba67eeb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "#     \"Single Vector Machine\": LinearSVC()\n",
    "    \n",
    "# }\n",
    "\n",
    "# metrics = [\"Accuracy\", \"Hamming Loss\", \"F1-Score\", \"Precision\", \"Recall\"]\n",
    "\n",
    "# results_df = pd.DataFrame(columns=[\"Model\"] + metrics)\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     # Fit the model on the resampled data\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Make predictions on test set\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     # Compute evaluation metrics\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     hamming_loss = hamming_loss(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred, average='macro')\n",
    "#     precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "#     recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "#     # Store results in the DataFrame\n",
    "#     results_df = results_df.append({\n",
    "#         \"Model\": model_name,\n",
    "#         \"Accuracy\": accuracy,\n",
    "#         \"Hamming Loss\": hamming_loss,\n",
    "#         \"F1-Score\": f1,\n",
    "#         \"Precision\": precision,\n",
    "#         \"Recall\": recall\n",
    "#     }, ignore_index=True)\n",
    "\n",
    "#     # Print evaluation metrics\n",
    "#     print(f\"Model: {model_name}\")\n",
    "#     print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "#     print(\"Hamming Loss: {:.3f}\".format(hamming_loss))\n",
    "#     print(\"F1-Score: {:.3f}\".format(f1))\n",
    "#     print(\"Precision: {:.3f}\".format(precision))\n",
    "#     print(\"Recall: {:.3f}\".format(recall))\n",
    "#     # print(\"Confusion Matrix:\")\n",
    "#     # print(confusion_matrix(y_test, y_pred))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad0035-c0f5-463b-988f-78dd6d7d821c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca4b43b-a1b2-42a4-af82-29349ebed264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.743\n",
      "Hamming Loss: 0.257\n",
      "F1-Score: 0.737\n",
      "Precision: 0.807\n",
      "Recall: 0.723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create the individual models\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create the voting classifier\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('dt', dt), ('rf', rf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Train the voting classifier\n",
    "voting.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = voting.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Hamming Loss: {:.3f}\".format(hamming_loss(y_test, y_pred)))\n",
    "print(\"F1-Score: {:.3f}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "print(\"Precision: {:.3f}\".format(precision_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "print(\"Recall: {:.3f}\".format(recall_score(y_test, y_pred, average='macro', zero_division=1)))\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a6e34e-ce93-41cf-af5f-794197f98f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51593789-dab9-4c41-8702-01f40199e639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the synopsis of the movie:  group of people travels to the middle earth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genre: Action,Adventure,Sci-Fi\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained Word2Vec model and TF-IDF vectorizer\n",
    "sentences = [doc.split() for doc in df['corpus']]\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_scores = tfidf_vectorizer.fit_transform(df['corpus'])\n",
    "\n",
    "# Combine Word2Vec vectors and TF-IDF scores\n",
    "hybrid_vectors = []\n",
    "for i, doc in enumerate(df['corpus']):\n",
    "    tfidf_scores_doc = tfidf_scores[i].toarray()[0]\n",
    "    word_vectors_doc = []\n",
    "    for word in doc.split():\n",
    "        if word in w2v_model.wv.key_to_index:\n",
    "            word_vector = w2v_model.wv[word]\n",
    "            if word in tfidf_vectorizer.vocabulary_:\n",
    "                word_vector_tfidf = word_vector * tfidf_scores_doc[tfidf_vectorizer.vocabulary_[word]]\n",
    "            else:\n",
    "                word_vector_tfidf = word_vector\n",
    "            word_vectors_doc.append(word_vector_tfidf)\n",
    "    if word_vectors_doc:\n",
    "        doc_vector = np.mean(word_vectors_doc, axis=0)\n",
    "    else:\n",
    "        doc_vector = np.zeros(w2v_model.vector_size)\n",
    "    hybrid_vectors.append(doc_vector)\n",
    "\n",
    "# Train the Random Forest Classifier on the entire dataset\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(hybrid_vectors, df['new_genre'])\n",
    "\n",
    "# Take user input and predict the genre\n",
    "user_input = input(\"Enter the synopsis of the movie: \")\n",
    "user_input_processed = tfidf_vectorizer.transform([user_input])\n",
    "user_input_vector = np.zeros(w2v_model.vector_size)\n",
    "for word in user_input.split():\n",
    "    if word in w2v_model.wv.key_to_index:\n",
    "        word_vector = w2v_model.wv[word]\n",
    "        if word in tfidf_vectorizer.vocabulary_:\n",
    "            word_vector_tfidf = word_vector * user_input_processed[0, tfidf_vectorizer.vocabulary_[word]]\n",
    "        else:\n",
    "            word_vector_tfidf = word_vector\n",
    "        user_input_vector += word_vector_tfidf\n",
    "user_input_vector /= len(user_input.split())\n",
    "\n",
    "genre_prediction = rfc.predict([user_input_vector])[0]\n",
    "\n",
    "print(\"Predicted genre:\", genre_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3728ce4-cc73-4f92-a719-ea92b2a06679",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed file size: 119891646 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Create a directory called 'new_pickle' if it does not exist\n",
    "if not os.path.exists('new_pickle'):\n",
    "    os.makedirs('new_pickle')\n",
    "\n",
    "# Pickle the objects\n",
    "with gzip.open(\"new_pickle/model.pklz\", \"wb\") as f:\n",
    "    pickle.dump(w2v_model, f)\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "    pickle.dump(rfc, f)\n",
    "\n",
    "# Get compressed file size\n",
    "file_size = os.path.getsize(\"new_pickle/model.pklz\")\n",
    "print(\"Compressed file size:\", file_size, \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9de12b-e4a0-4872-a236-5d5510acd592",
   "metadata": {},
   "source": [
    "## Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aef4f3-6690-4709-9b33-936622a55a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "# Load the pickled objects\n",
    "with gzip.open(\"new_pickle/model.pklz\", \"rb\") as f:\n",
    "    w2v_model = pickle.load(f)\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "    rfc = pickle.load(f)\n",
    "\n",
    "def predict_genre(synopsis):\n",
    "    # Process user input\n",
    "    user_input_processed = tfidf_vectorizer.transform([synopsis])\n",
    "    user_input_vector = np.zeros(w2v_model.vector_size)\n",
    "    for word in synopsis.split():\n",
    "        if word in w2v_model.wv.key_to_index:\n",
    "            word_vector = w2v_model.wv[word]\n",
    "            if word in tfidf_vectorizer.vocabulary_:\n",
    "                word_vector_tfidf = word_vector * user_input_processed[0, tfidf_vectorizer.vocabulary_[word]]\n",
    "            else:\n",
    "                word_vector_tfidf = word_vector\n",
    "            user_input_vector += word_vector_tfidf\n",
    "    user_input_vector /= len(synopsis.split())\n",
    "\n",
    "    # Predict the genre\n",
    "    genre_prediction = rfc.predict([user_input_vector])[0]\n",
    "    return genre_prediction\n",
    "\n",
    "\n",
    "# Create the Gradio interface\n",
    "synopsis_input = gr.Textbox(label=\"Enter the synopsis of the movie\")\n",
    "genre_output = gr.Textbox(label=\"Predicted genre\")\n",
    "gr.Interface(fn=predict_genre, inputs=synopsis_input, outputs=genre_output, title=\"GenreOracle\",\n",
    "    description=\"Here's a sample synopsis\\n aliens in planet pandora protecting their world from human\\nfamily members encounters their teenage kids in love\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5795e6d0-2ea7-4d02-b6bf-3ab50877acd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gradio as gr\n",
    "# import pickle\n",
    "# import gzip\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the pickled objects\n",
    "# with gzip.open(\"new_pickle/model.pklz\", \"rb\") as f:\n",
    "#     w2v_model = pickle.load(f)\n",
    "#     tfidf_vectorizer = pickle.load(f)\n",
    "#     rfc = pickle.load(f)\n",
    "\n",
    "# # Load the movie data from the CSV file\n",
    "# movie_data = pd.read_csv(\"finalmovie.csv\")\n",
    "\n",
    "# def predict_genre(synopsis):\n",
    "#     # Process user input\n",
    "#     user_input_processed = tfidf_vectorizer.transform([synopsis])\n",
    "#     user_input_vector = np.zeros(w2v_model.vector_size)\n",
    "#     for word in synopsis.split():\n",
    "#         if word in w2v_model.wv.key_to_index:\n",
    "#             word_vector = w2v_model.wv[word]\n",
    "#             if word in tfidf_vectorizer.vocabulary_:\n",
    "#                 word_vector_tfidf = word_vector * user_input_processed[0, tfidf_vectorizer.vocabulary_[word]]\n",
    "#             else:\n",
    "#                 word_vector_tfidf = word_vector\n",
    "#             user_input_vector += word_vector_tfidf\n",
    "#     user_input_vector /= len(synopsis.split())\n",
    "\n",
    "#     # Predict the genre\n",
    "#     genre_prediction = rfc.predict([user_input_vector])[0]\n",
    "    \n",
    "#     # Filter the movie titles based on the predicted genre\n",
    "#     movie_titles = movie_data[movie_data['new_genre'] == genre_prediction]['title'].tolist()\n",
    "    \n",
    "#     # Return the predicted genre and movie titles\n",
    "#     return genre_prediction, movie_titles\n",
    "\n",
    "\n",
    "# # Create the Gradio interface\n",
    "# synopsis_input = gr.Textbox(label=\"Enter the synopsis of the movie\")\n",
    "# genre_output = gr.Textbox(label=\"Predicted Genre\")\n",
    "# titles_output = gr.Textbox(label=\"Suggested Movie Titles\")\n",
    "# gr.Interface(fn=predict_genre, inputs=synopsis_input, outputs=[genre_output, titles_output], title=\"GenreOracle\",\n",
    "#     description=\"Here's a sample synopsis\\n aliens in planet pandora protecting their world from human\\nfamily members encounters their teenage kids in love\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7c3665-1e50-4b9d-bd35-d7506a0bed22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickled objects\n",
    "with gzip.open(\"new_pickle/model.pklz\", \"rb\") as f:\n",
    "    w2v_model = pickle.load(f)\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "    rfc = pickle.load(f)\n",
    "\n",
    "# Load the movie data from the CSV file\n",
    "movie_data = pd.read_csv(\"finalmovie.csv\")\n",
    "\n",
    "def predict_genre(synopsis):\n",
    "    # Process user input\n",
    "    user_input_processed = tfidf_vectorizer.transform([synopsis])\n",
    "    user_input_vector = np.zeros(w2v_model.vector_size)\n",
    "    for word in synopsis.split():\n",
    "        if word in w2v_model.wv.key_to_index:\n",
    "            word_vector = w2v_model.wv[word]\n",
    "            if word in tfidf_vectorizer.vocabulary_:\n",
    "                word_vector_tfidf = word_vector * user_input_processed[0, tfidf_vectorizer.vocabulary_[word]]\n",
    "            else:\n",
    "                word_vector_tfidf = word_vector\n",
    "            user_input_vector += word_vector_tfidf\n",
    "    user_input_vector /= len(synopsis.split())\n",
    "\n",
    "    # Predict the genre\n",
    "    genre_prediction = rfc.predict([user_input_vector])[0]\n",
    "    \n",
    "    # Filter the movie titles based on the predicted genre\n",
    "    movie_titles = movie_data[movie_data['new_genre'] == genre_prediction]['title'].tolist()\n",
    "    \n",
    "    # Limit the number of movie titles displayed to 10\n",
    "    if len(movie_titles) > 10:\n",
    "        movie_titles = movie_titles[:10]\n",
    "    \n",
    "    # Format the movie titles as a bulleted list\n",
    "    movie_titles_bullet = \"\\n\".join([f\"- {title}\" for title in movie_titles])\n",
    "    \n",
    "    # Return the predicted genre and movie titles\n",
    "    return genre_prediction, movie_titles_bullet\n",
    "\n",
    "\n",
    "# Create the Gradio interface\n",
    "synopsis_input = gr.Textbox(label=\"Enter the synopsis of the movie\")\n",
    "genre_output = gr.Textbox(label=\"Predicted genre\")\n",
    "titles_output = gr.Textbox(label=\"Movie titles with the predicted genre (up to 10)\")\n",
    "gr.Interface(fn=predict_genre, inputs=synopsis_input, outputs=[genre_output, titles_output], title=\"GenreOracle\",\n",
    "    description=\"Here's a sample synopsis\\n aliens in planet pandora protecting their world from human\\nfamily members encounters their teenage kids in love\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4130e-b3f6-49fe-9833-e8e88e15aea0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Final APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aded400-3c79-46b8-8fe5-99ac8970c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with gzip.open(\"new_pickle/model.pklz\", \"rb\") as f:\n",
    "    w2v_model = pickle.load(f)\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "    rfc = pickle.load(f)\n",
    "\n",
    "\n",
    "movie_data = pd.read_csv(\"finalmovie.csv\")\n",
    "\n",
    "def predict_genre(synopsis, num_titles):\n",
    "    # Process user input\n",
    "    user_input_processed = tfidf_vectorizer.transform([synopsis])\n",
    "    user_input_vector = np.zeros(w2v_model.vector_size)\n",
    "    for word in synopsis.split():\n",
    "        if word in w2v_model.wv.key_to_index:\n",
    "            word_vector = w2v_model.wv[word]\n",
    "            if word in tfidf_vectorizer.vocabulary_:\n",
    "                word_vector_tfidf = word_vector * user_input_processed[0, tfidf_vectorizer.vocabulary_[word]]\n",
    "            else:\n",
    "                word_vector_tfidf = word_vector\n",
    "            user_input_vector += word_vector_tfidf\n",
    "    user_input_vector /= len(synopsis.split())\n",
    "\n",
    "    # Predict the genre\n",
    "    genre_prediction = rfc.predict([user_input_vector])[0]\n",
    "    \n",
    "    # Filter the movie titles based on the predicted genre\n",
    "    movie_titles = movie_data[movie_data['new_genre'] == genre_prediction]['title'].tolist()\n",
    "    \n",
    "    # Limit the number of movie titles displayed based on the user input\n",
    "    if len(movie_titles) > num_titles:\n",
    "        movie_titles = movie_titles[:num_titles]\n",
    "    \n",
    "    # Format the movie titles as a bulleted list\n",
    "    movie_titles_bullet = \"\\n\".join([f\"- {title}\" for title in movie_titles])\n",
    "    \n",
    "    # Return the predicted genre and movie titles\n",
    "    return genre_prediction, movie_titles_bullet\n",
    "\n",
    "\n",
    "# Create the Gradio interface with a Slider for the number of suggested movie titles\n",
    "synopsis_input = gr.Textbox(label=\"Enter the synopsis of the movie\")\n",
    "num_titles_input = gr.Slider(minimum=5, maximum=20, step=5, label=\"Number of suggested movie titles\")\n",
    "genre_output = gr.Textbox(label=\"Predicted genre\")\n",
    "titles_output = gr.Textbox(label=\"Suggested movie titles with the predicted genre\")\n",
    "gr.Interface(fn=predict_genre, inputs=[synopsis_input, num_titles_input], outputs=[genre_output, titles_output], \n",
    "             title=\"GenreOracle (v1.0-beta1)\",\n",
    "             description=\"Enter the synopsis of a movie and get suggestions for similar movies\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f4e6c-7920-477f-8105-0cd87a3977e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bb803-0cd3-4cb1-92a1-feac4b7657d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106149c-2d8f-4438-8224-7e0d94abb33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc435781-7c0c-4c7e-835e-6cc906a86430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01479c27-6d72-4ed3-a634-7d2d00ad507f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
